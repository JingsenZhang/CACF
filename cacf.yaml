# model config
train_batch_size: 1024
learning_rate: 0.01
embedding_size: 32
mlp_hidden_size: [64,32,16]
dropout_prob: 0.1
attention_size: 25
t: 1
loss_weight1: 0.1
loss_weight2: 0.5
distance: 1
check_weight: 1

# general
gpu_id: 1
use_gpu: True
seed: 2020
state: INFO
reproducibility: True
data_path: 'dataset/'
checkpoint_dir: 'saved'
show_progress: False

# training settings
epochs: 100
learner: adam
training_neg_sample_num: 1
training_neg_sample_distribution: uniform
eval_step: 1
stopping_step: 5
clip_grad_norm: ~
# clip_grad_norm:  {'max_norm': 5, 'norm_type': 2}
weight_decay: 0.0
